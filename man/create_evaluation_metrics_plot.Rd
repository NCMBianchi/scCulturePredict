% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/evaluation.R
\name{create_evaluation_metrics_plot}
\alias{create_evaluation_metrics_plot}
\title{Plot evaluation metrics}
\usage{
create_evaluation_metrics_plot(
  evaluation_results,
  plot_type = "confusion",
  title = NULL,
  color_palette = NULL,
  verbose = TRUE
)
}
\arguments{
\item{evaluation_results}{List. Results from evaluate_predictions().}

\item{plot_type}{Character. Type of plot to create. Options are:
\itemize{
  \item "confusion": Confusion matrix heatmap
  \item "metrics": Bar plot of precision, recall, and F1 scores
  \item "roc": ROC curve (if probabilities are available)
  \item "pr": Precision-recall curve (if probabilities are available)
}}

\item{title}{Character. Title for the plot (default: NULL).}

\item{color_palette}{Character vector. Colors to use for the plot
(default: NULL, uses default palette).}

\item{verbose}{Logical. Whether to print progress messages (default: TRUE).}
}
\value{
A ggplot object containing the requested visualization.
}
\description{
Creates visualizations of prediction evaluation metrics.
This function generates various plots to help understand the performance
of cell type predictions.
}
\details{
The function performs the following steps:
\enumerate{
  \item Validates input parameters and data
  \item Prepares data for plotting
  \item Creates the requested visualization
  \item Applies custom styling if specified
}

This function creates various types of evaluation plots to visualize prediction performance.
It supports four different plot types:
\itemize{
  \item "confusion": A heatmap visualization of the confusion matrix
  \item "metrics": A bar plot of precision, recall, and F1 scores
  \item "roc": A receiver operating characteristic curve
  \item "pr": A precision-recall curve
}

The function validates all inputs and checks that the required data for the
specified plot type is available in the evaluation_results. It uses ggplot2
for visualization and applies appropriate styling and formatting based on the
plot type and user-provided parameters.

For the confusion matrix plot, cell counts are shown as text labels, while the
metrics plot displays precision, recall, and F1 scores with customizable colors.
ROC and PR curves visualize classifier performance across different thresholds.
}
\examples{
# Example with mock evaluation metrics
metrics_data <- data.frame(
  metric = rep(c("Accuracy", "Precision", "Recall", "F1"), 3),
  value = c(0.85, 0.82, 0.88, 0.85, 0.79, 0.77, 0.81, 0.79, 0.91, 0.89, 0.93, 0.91),
  method = rep(c("Method1", "Method2", "Method3"), each = 4)
)
plot <- create_evaluation_metrics_plot(metrics_data)
}
\seealso{
\code{\link{evaluate_predictions}} for calculating evaluation metrics
}
